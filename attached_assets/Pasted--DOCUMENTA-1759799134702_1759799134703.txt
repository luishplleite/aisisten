================================================================================
          DOCUMENTAÃ‡ÃƒO COMPLETA - INTEGRAÃ‡ÃƒO OPENAI API
                    TimePulse AI - Sistema de GestÃ£o
================================================================================

ğŸ“‹ ÃNDICE
1. VisÃ£o Geral
2. ConfiguraÃ§Ã£o da API
3. Modelo e ParÃ¢metros
4. Endpoints do Sistema
5. Assistente Virtual Ana
6. Assistente Administrativo
7. Sistema MCP (Model Context Protocol)
8. Prompts Personalizados
9. Rate Limiting e SeguranÃ§a
10. Troubleshooting

================================================================================
1. VISÃƒO GERAL
================================================================================

O TimePulse AI utiliza a API OpenAI para alimentar seus assistentes virtuais
inteligentes que interagem com clientes e administradores.

COMPONENTES PRINCIPAIS:
- Ana - Assistente Virtual para clientes (atendimento, pedidos, cardÃ¡pio)
- Assistente Administrativo (gerenciamento, anÃ¡lises, suporte)
- Sistema MCP - IntegraÃ§Ã£o com banco de dados para respostas contextuais

MODELO UTILIZADO: GPT-5-mini
PROVIDER: OpenAI API (https://api.openai.com/v1)

CARACTERÃSTICAS:
âœ“ Chat conversacional com memÃ³ria de contexto
âœ“ RaciocÃ­nio adaptÃ¡vel (reasoning_effort)
âœ“ IntegraÃ§Ã£o com dados do restaurante
âœ“ CriaÃ§Ã£o automÃ¡tica de pedidos
âœ“ Consulta de cardÃ¡pio
âœ“ Prompts personalizÃ¡veis por restaurante

================================================================================
2. CONFIGURAÃ‡ÃƒO DA API
================================================================================

2.1 VARIÃVEIS DE AMBIENTE
---------------------------

VariÃ¡vel ObrigatÃ³ria:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ OPENAI_API_KEY                                              â”‚
â”‚ DescriÃ§Ã£o: Chave de API da OpenAI                          â”‚
â”‚ Formato: sk-proj-xxxxxxxxxxxxxxxxxxxxxxxxxxxxx             â”‚
â”‚ SeguranÃ§a: NUNCA expor ao frontend                         â”‚
â”‚ Local: VariÃ¡vel de ambiente do servidor                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

VerificaÃ§Ã£o da Chave:
```javascript
const apiKey = process.env.OPENAI_API_KEY;
if (!apiKey) {
    console.error('âŒ OPENAI_API_KEY nÃ£o configurada');
    return res.status(500).json({ 
        error: 'ConfiguraÃ§Ã£o da OpenAI API nÃ£o encontrada' 
    });
}
```

2.2 ARQUIVO DE CONFIGURAÃ‡ÃƒO
-----------------------------

Arquivo: api/config/openai

Estrutura:
```json
{
    "status": "secure_config",
    "configured": false,
    "environment": "production",
    "note": "API keys are now managed via environment variables for security. Using OpenAI API for GPT-5-mini access",
    "required_env_vars": ["OPENAI_API_KEY"],
    "baseUrl": "https://api.openai.com/v1",
    "features": {
        "chat": true,
        "completions": true,
        "embeddings": true,
        "images": false,
        "audio": false,
        "reasoning": true,
        "tools": true,
        "streaming": true
    },
    "models": {
        "chat": "gpt-5-mini",
        "completion": "gpt-5-mini",
        "embedding": "text-embedding-ada-002"
    },
    "parameters": {
        "reasoning_effort": "medium",
        "max_completion_tokens": 4096,
        "stream": false,
        "response_format": {"type": "text"}
    },
    "reasoning_levels": {
        "minimal": "Para instruÃ§Ãµes claras e diretas",
        "low": "Para tarefas simples com raciocÃ­nio bÃ¡sico", 
        "medium": "EquilÃ­brio entre qualidade e velocidade (padrÃ£o)",
        "high": "Para anÃ¡lises complexas e raciocÃ­nio aprofundado"
    },
    "limits": {
        "requests_per_minute": 60,
        "tokens_per_minute": 40000
    }
}
```

2.3 ENDPOINT DE CONFIGURAÃ‡ÃƒO
------------------------------

Endpoint: GET /api/config/openai
AutenticaÃ§Ã£o: NÃ£o requerida (dados pÃºblicos sanitizados)
Cache-Control: no-cache

Response (server.js - linha 1494):
```json
{
    "status": "ok",
    "configured": true,
    "environment": "production",
    "baseUrl": "https://api.openai.com/v1",
    "provider": "OpenAI API",
    "model": "gpt-5-mini",
    "features": {
        "chat": true,
        "completions": true,
        "embeddings": true,
        "images": false,
        "audio": false,
        "reasoning": true,
        "tools": true,
        "streaming": true
    },
    "models": {
        "chat": "gpt-5-mini",
        "completion": "gpt-5-mini",
        "embedding": "text-embedding-ada-002"
    },
    "parameters": {
        "reasoning_effort": "medium",
        "max_completion_tokens": 4096,
        "stream": false,
        "response_format": {"type": "text"}
    },
    "reasoning_levels": {
        "minimal": "Para instruÃ§Ãµes claras e diretas",
        "low": "Para tarefas simples com raciocÃ­nio bÃ¡sico", 
        "medium": "EquilÃ­brio entre qualidade e velocidade (padrÃ£o)",
        "high": "Para anÃ¡lises complexas e raciocÃ­nio aprofundado"
    },
    "limits": {
        "requests_per_minute": 60,
        "tokens_per_minute": 40000
    },
    "timestamp": "2025-10-07T00:00:00.000Z"
}
```

IMPORTANTE: A chave da API (OPENAI_API_KEY) NÃƒO Ã© incluÃ­da na resposta
por questÃµes de seguranÃ§a.

================================================================================
3. MODELO E PARÃ‚METROS
================================================================================

3.1 MODELO PRINCIPAL
---------------------

MODELO: gpt-5-mini
PROVIDER: OpenAI
ENDPOINT: https://api.openai.com/v1/chat/completions
MÃ‰TODO: POST

CARACTERÃSTICAS DO GPT-5-MINI:
- RaciocÃ­nio avanÃ§ado (reasoning capabilities)
- Suporte a tools/functions
- Contexto de atÃ© 128k tokens
- Respostas rÃ¡pidas e eficientes
- Custo-benefÃ­cio otimizado

3.2 PARÃ‚METROS PADRÃƒO
----------------------

```javascript
{
    model: 'gpt-5-mini',                    // SEMPRE gpt-5-mini
    messages: [...],                         // Array de mensagens
    max_completion_tokens: 4096,             // MÃ¡ximo de tokens na resposta
    temperature: 0.7,                        // Criatividade (0.0 a 2.0)
    stream: false,                           // Sem streaming
    reasoning_effort: 'medium'               // NÃ­vel de raciocÃ­nio
}
```

PARÃ‚METROS DETALHADOS:

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ model (string) - OBRIGATÃ“RIO                                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Valor fixo: "gpt-5-mini"                                         â”‚
â”‚ DescriÃ§Ã£o: Modelo de linguagem a ser usado                      â”‚
â”‚ Importante: NUNCA usar outro modelo                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ messages (array) - OBRIGATÃ“RIO                                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Estrutura:                                                       â”‚
â”‚ [                                                                â”‚
â”‚   {                                                              â”‚
â”‚     role: "system",                                              â”‚
â”‚     content: "VocÃª Ã© Ana, assistente virtual..."                â”‚
â”‚   },                                                             â”‚
â”‚   {                                                              â”‚
â”‚     role: "user",                                                â”‚
â”‚     content: "Qual Ã© o cardÃ¡pio?"                                â”‚
â”‚   },                                                             â”‚
â”‚   {                                                              â”‚
â”‚     role: "assistant",                                           â”‚
â”‚     content: "Aqui estÃ¡ nosso cardÃ¡pio..."                       â”‚
â”‚   }                                                              â”‚
â”‚ ]                                                                â”‚
â”‚                                                                  â”‚
â”‚ Roles disponÃ­veis:                                               â”‚
â”‚ - system: InstruÃ§Ãµes e contexto do assistente                   â”‚
â”‚ - user: Mensagens do usuÃ¡rio                                    â”‚
â”‚ - assistant: Respostas anteriores da IA                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ max_completion_tokens (integer) - OPCIONAL                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Valor padrÃ£o: 4096                                               â”‚
â”‚ DescriÃ§Ã£o: NÃºmero mÃ¡ximo de tokens na resposta                  â”‚
â”‚ Range: 1 a 128000 (modelo suporta atÃ© 128k)                     â”‚
â”‚ Uso tÃ­pico: 4096 tokens â‰ˆ 3000 palavras                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ temperature (float) - OPCIONAL                                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Valor padrÃ£o: 0.7                                                â”‚
â”‚ Range: 0.0 a 2.0                                                 â”‚
â”‚ DescriÃ§Ã£o: Controla a criatividade/aleatoriedade                â”‚
â”‚                                                                  â”‚
â”‚ Valores recomendados:                                            â”‚
â”‚ - 0.0 a 0.3: Respostas determinÃ­sticas e precisas               â”‚
â”‚ - 0.4 a 0.7: Balanceado (padrÃ£o do sistema)                     â”‚
â”‚ - 0.8 a 1.2: Criativo e variado                                 â”‚
â”‚ - 1.3 a 2.0: Muito criativo (pode ser incoerente)               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ stream (boolean) - OPCIONAL                                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Valor padrÃ£o: false                                              â”‚
â”‚ DescriÃ§Ã£o: Habilita streaming de respostas                      â”‚
â”‚                                                                  â”‚
â”‚ false: Aguarda resposta completa antes de retornar              â”‚
â”‚ true: Envia resposta em chunks (atualmente desabilitado)        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ reasoning_effort (string) - ESPECÃFICO DO GPT-5-MINI             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Valor padrÃ£o: "medium"                                           â”‚
â”‚ Valores possÃ­veis:                                               â”‚
â”‚                                                                  â”‚
â”‚ "minimal" - Para instruÃ§Ãµes claras e diretas                     â”‚
â”‚           - Respostas rÃ¡pidas                                    â”‚
â”‚           - Menor consumo de tokens                              â”‚
â”‚                                                                  â”‚
â”‚ "low"     - Para tarefas simples com raciocÃ­nio bÃ¡sico          â”‚
â”‚           - Respostas diretas                                    â”‚
â”‚           - Baixo consumo                                        â”‚
â”‚                                                                  â”‚
â”‚ "medium"  - EquilÃ­brio entre qualidade e velocidade (PADRÃƒO)    â”‚
â”‚           - Uso geral                                            â”‚
â”‚           - Melhor custo-benefÃ­cio                               â”‚
â”‚                                                                  â”‚
â”‚ "high"    - Para anÃ¡lises complexas e raciocÃ­nio aprofundado    â”‚
â”‚           - Respostas mais elaboradas                            â”‚
â”‚           - Maior consumo de tokens                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

3.3 LIMITES DE USO
-------------------

Configurados no sistema:
- requests_per_minute: 60
- tokens_per_minute: 40000

Rate Limiting (ver seÃ§Ã£o 9):
- Clientes: 30 requests / 60 segundos
- Administradores: Sem limite especÃ­fico
- Sistema MCP: Incluso nas requisiÃ§Ãµes de chat

================================================================================
4. ENDPOINTS DO SISTEMA
================================================================================

4.1 ENDPOINT DE CHAT DO ASSISTENTE (CLIENTES)
----------------------------------------------

ENDPOINT: POST /api/assistant/chat
Arquivo: server.js (linha 3839)
AutenticaÃ§Ã£o: authenticateEvolutionAPI
Rate Limit: 30 requisiÃ§Ãµes / 60 segundos

REQUEST BODY:
```json
{
    "messages": [
        {
            "role": "system",
            "content": "VocÃª Ã© Ana, assistente virtual..."
        },
        {
            "role": "user",
            "content": "Qual Ã© o cardÃ¡pio de hoje?"
        }
    ],
    "model": "gpt-5-mini",
    "reasoning_effort": "medium",
    "max_completion_tokens": 4096,
    "temperature": 0.7,
    "restaurant_id": "uuid-do-restaurante",
    "session_id": "sessao-unica-do-cliente"
}
```

RESPONSE (Sucesso):
```json
{
    "response": "OlÃ¡! Aqui estÃ¡ nosso cardÃ¡pio delicioso...",
    "model_used": "gpt-5-mini",
    "reasoning_effort": "medium",
    "mcp_activated": false,
    "mcp_data": null
}
```

RESPONSE (Com MCP ativado):
```json
{
    "response": "Com base nos dados do sistema, temos 15 produtos...",
    "model_used": "gpt-5-mini",
    "reasoning_effort": "medium",
    "mcp_activated": true,
    "mcp_data": {
        "count": 15,
        "data": [...]
    }
}
```

RESPONSE (Erro):
```json
{
    "error": "Erro no processamento da IA",
    "details": "..."
}
```

FLUXO DE PROCESSAMENTO:

1. ValidaÃ§Ã£o de autenticaÃ§Ã£o e restaurant_id
2. VerificaÃ§Ã£o da OPENAI_API_KEY
3. DetecÃ§Ã£o de palavras-chave MCP (opcional)
4. Se MCP detectado:
   - Executar consulta ao banco de dados
   - Adicionar dados MCP ao contexto da mensagem
5. Chamar OpenAI API:
   ```javascript
   const gptResponse = await fetch('https://api.openai.com/v1/chat/completions', {
       method: 'POST',
       headers: {
           'Authorization': `Bearer ${apiKey}`,
           'Content-Type': 'application/json'
       },
       body: JSON.stringify({
           model: 'gpt-5-mini',
           messages: messages,
           max_completion_tokens: max_completion_tokens || 4096,
           temperature: temperature || 0.7,
           stream: false
       })
   });
   ```
6. Processar resposta da OpenAI
7. Retornar ao cliente com metadados

CÃ“DIGO COMPLETO (server.js - linha 3839-3949):
```javascript
app.post('/api/assistant/chat', authenticateEvolutionAPI, rateLimitEvolutionAPI(30, 60000), async (req, res) => {
    try {
        const { messages, model, reasoning_effort, max_completion_tokens, temperature, restaurant_id, session_id } = req.body;

        // Verificar se o usuÃ¡rio tem acesso a este restaurante
        if (restaurant_id && req.session.restaurantId !== restaurant_id) {
            return res.status(403).json({
                error: "Acesso nÃ£o autorizado"
            });
        }
        
        if (!messages || !Array.isArray(messages)) {
            return res.status(400).json({ error: 'Mensagens sÃ£o obrigatÃ³rias' });
        }

        const apiKey = process.env.OPENAI_API_KEY;
        if (!apiKey) {
            return res.status(500).json({ error: 'ConfiguraÃ§Ã£o da OpenAI API nÃ£o encontrada' });
        }

        // IntegraÃ§Ã£o MCP (ver seÃ§Ã£o 7)
        let mcpData = null;
        let mcpActivated = false;
        const lastMessage = messages[messages.length - 1];
        if (lastMessage && lastMessage.role === 'user' && detectMCPKeywords(lastMessage.content)) {
            // ... lÃ³gica MCP
        }

        // Chamar OpenAI API
        const gptResponse = await fetch('https://api.openai.com/v1/chat/completions', {
            method: 'POST',
            headers: {
                'Authorization': `Bearer ${apiKey}`,
                'Content-Type': 'application/json'
            },
            body: JSON.stringify({
                model: 'gpt-5-mini',
                messages: messages,
                max_completion_tokens: max_completion_tokens || 4096,
                temperature: temperature || 0.7,
                stream: false
            })
        });

        const data = await gptResponse.json();
        const responseMessage = data.choices?.[0]?.message?.content || 'Desculpe, nÃ£o consegui processar sua mensagem.';

        res.json({
            response: responseMessage,
            model_used: 'gpt-5-mini',
            reasoning_effort: reasoning_effort || 'medium',
            mcp_activated: mcpActivated,
            mcp_data: mcpActivated ? mcpData : null
        });

    } catch (error) {
        console.error('âŒ Erro no endpoint do assistente:', error);
        res.status(500).json({ error: 'Erro interno do servidor' });
    }
});
```

4.2 ENDPOINT DE CHAT ADMINISTRATIVO
------------------------------------

ENDPOINT: POST /api/admin/assistant/chat
Arquivo: server.js (linha 2639)
AutenticaÃ§Ã£o: authenticateAdmin
Rate Limit: NÃ£o especificado (administrativo)

REQUEST BODY:
```json
{
    "messages": [...],
    "model": "gpt-5-mini",
    "reasoning_effort": "medium",
    "max_completion_tokens": 4096,
    "temperature": 0.7,
    "restaurant_id": "uuid-do-restaurante",
    "session_id": "admin-12345"
}
```

RESPONSE:
```json
{
    "response": "Como administrador, vocÃª pode...",
    "model_used": "gpt-5-mini",
    "reasoning_effort": "medium",
    "session_id": "admin-12345",
    "admin_mode": true,
    "usage": {
        "prompt_tokens": 150,
        "completion_tokens": 300,
        "total_tokens": 450
    },
    "timestamp": "2025-10-07T00:00:00.000Z"
}
```

DIFERENÃ‡AS DO ENDPOINT DE CLIENTES:
- AutenticaÃ§Ã£o administrativa obrigatÃ³ria
- Retorna dados de usage (consumo de tokens)
- Flag admin_mode: true
- Sem integraÃ§Ã£o MCP
- Sem rate limiting agressivo

CÃ“DIGO (server.js - linha 2639-2716):
```javascript
app.post('/api/admin/assistant/chat', authenticateAdmin, async (req, res) => {
    try {
        const { messages, model, reasoning_effort, max_completion_tokens, temperature, restaurant_id, session_id } = req.body;

        const finalModel = 'gpt-5-mini'; // SEMPRE gpt-5-mini
        const finalReasoningEffort = reasoning_effort || 'medium';
        const finalMaxTokens = max_completion_tokens || 4096;
        const finalSessionId = session_id || `admin-${Date.now()}`;

        const apiKey = process.env.OPENAI_API_KEY;
        if (!apiKey) {
            return res.status(500).json({
                error: 'OpenAI API nÃ£o configurada'
            });
        }

        const response = await fetch('https://api.openai.com/v1/chat/completions', {
            method: 'POST',
            headers: {
                'Content-Type': 'application/json',
                'Authorization': `Bearer ${apiKey}`
            },
            body: JSON.stringify({
                model: finalModel,
                messages: messages,
                max_completion_tokens: finalMaxTokens,
                stream: false
            })
        });

        const data = await response.json();
        const aiResponse = data.choices[0].message.content;

        res.json({
            response: aiResponse,
            model_used: finalModel,
            reasoning_effort: finalReasoningEffort,
            session_id: finalSessionId,
            admin_mode: true,
            usage: data.usage || {},
            timestamp: new Date().toISOString()
        });

    } catch (error) {
        res.status(500).json({
            error: 'Erro interno do servidor',
            details: error.message
        });
    }
});
```

4.3 ENDPOINT DE STATUS/HEALTH
------------------------------

ENDPOINT: GET /api/health
Arquivo: server.js (linha 1710)
AutenticaÃ§Ã£o: NÃ£o requerida

Verifica conectividade com OpenAI:

```javascript
try {
    const openaiKey = process.env.OPENAI_API_KEY;
    if (openaiKey) {
        const OpenAI = require('openai');
        const openai = new OpenAI({ apiKey: openaiKey });
        
        // Listar modelos com timeout de 5 segundos
        const modelsPromise = openai.models.list();
        const timeoutPromise = new Promise((_, reject) => 
            setTimeout(() => reject(new Error('timeout')), 5000)
        );
        
        await Promise.race([modelsPromise, timeoutPromise]);
        services.openai = "connected";
    } else {
        services.openai = "not_configured";
    }
} catch (error) {
    services.openai = error.message.includes('timeout') ? "timeout" : "error";
}
```

RESPONSE:
```json
{
    "status": "ok",
    "services": {
        "openai": "connected",
        "supabase": "connected",
        "evolution": "connected",
        "mapbox": "connected"
    }
}
```

Status possÃ­veis para OpenAI:
- "connected": API funcionando normalmente
- "not_configured": OPENAI_API_KEY nÃ£o configurada
- "timeout": Timeout na conexÃ£o
- "error": Erro na conexÃ£o

================================================================================
5. ASSISTENTE VIRTUAL ANA
================================================================================

5.1 CLASSE AnaAssistant
------------------------

Arquivo: public/js/assistente.js
Linha inicial: 4

ESTRUTURA DA CLASSE:
```javascript
class AnaAssistant {
    constructor() {
        this.messages = [];                  // HistÃ³rico de mensagens
        this.chatMemory = new Map();         // MemÃ³ria de contexto
        this.isTyping = false;               // Estado de digitaÃ§Ã£o
        this.restaurantData = null;          // Dados do restaurante
        this.customerData = null;            // Dados do cliente
        this.currentOrder = null;            // Pedido em andamento
        this.sessionId = null;               // ID da sessÃ£o persistente
        this.messageCount = 0;               // Contador de mensagens
        this.ordersCreated = 0;              // Pedidos criados
        this.customSystemPrompt = null;      // Prompt personalizado
        this.systemPromptLoaded = false;     // Flag de carregamento
        
        // ConfiguraÃ§Ãµes
        this.config = {
            assistantName: "Ana",
            assistantRole: "Assistente Virtual",
            tone: "calorosa, humanizada brasileira",
            language: "pt-BR",
            restaurantSchedule: "das 18:00 Ã s 23:00"
        };
        
        // Estados da conversa
        this.conversationState = {
            stage: 'initial',
            waitingForAddressConfirmation: false,
            waitingForPayment: false,
            currentProduct: null,
            selectedAdditionals: [],
            pendingOrder: null
        };
    }
}
```

5.2 INICIALIZAÃ‡ÃƒO
------------------

MÃ©todo: async init()
Linha: 38

Fluxo:
1. Verificar autenticaÃ§Ã£o
2. Carregar dados do restaurante
3. Inicializar Supabase
4. Configurar event listeners
5. Carregar prompt personalizado
6. Carregar memÃ³ria de chat
7. Carregar dados do cliente (se disponÃ­vel)
8. Inicializar chat

CÃ³digo:
```javascript
async init() {
    try {
        console.log('ğŸš€ Inicializando Ana - Assistente Virtual...');
        
        // Verificar autenticaÃ§Ã£o
        if (!window.SECURE_INSTANCE_MANAGER?.isAuthenticated()) {
            window.location.href = '../login.html';
            return;
        }

        // Carregar dados do restaurante
        await this.loadRestaurantData();
        
        // Carregar configuraÃ§Ã£o do Supabase
        await this.initializeSupabase();
        
        // Configurar interface
        this.setupEventListeners();
        
        // Carregar prompt personalizado (se existir)
        await this.loadCustomSystemPrompt();
        
        // Verificar memÃ³ria de chat existente
        await this.loadChatMemory();
        
        // Tentar obter telefone do cliente e carregar dados
        const customerPhone = this.getCustomerPhoneFromContext();
        if (customerPhone) {
            await this.loadCustomerData(customerPhone);
        }
        
        // Inicializar chat
        this.initializeChat();
        
        console.log('âœ… Ana inicializada com sucesso');
        
    } catch (error) {
        console.error('âŒ Erro ao inicializar Ana:', error);
        this.showError('Erro ao inicializar o assistente. Recarregue a pÃ¡gina.');
    }
}
```

5.3 ENVIO DE MENSAGENS
-----------------------

MÃ©todo: async sendMessage()
Linha: 481

Fluxo:
1. Validar mensagem e estado
2. Adicionar mensagem do usuÃ¡rio Ã  interface
3. Mostrar indicador de "digitando"
4. Processar mensagem:
   - Verificar ativaÃ§Ã£o MCP
   - Construir contexto
   - Chamar GPT-5-mini
   - Processar resposta
5. Atualizar memÃ³ria
6. Exibir resposta

CÃ³digo:
```javascript
async sendMessage() {
    const messageInput = document.getElementById('messageInput');
    const message = messageInput.value.trim();
    
    if (!message || this.isTyping) return;

    // Adicionar mensagem do usuÃ¡rio
    this.addMessage('user', message);
    messageInput.value = '';
    messageInput.style.height = 'auto';
    
    // Indicador de digitaÃ§Ã£o
    this.isTyping = true;
    this.showTypingIndicator();
    
    try {
        // Processar mensagem
        const response = await this.processMessage(message);
        
        // Adicionar resposta
        this.addMessage('assistant', response);
        this.messageCount++;
        
    } catch (error) {
        console.error('âŒ Erro ao processar mensagem:', error);
        this.addMessage('assistant', 'Desculpe, tive um problema. Por favor, tente novamente.');
    } finally {
        this.isTyping = false;
        this.hideTypingIndicator();
        messageInput.focus();
    }
}
```

5.4 CHAMADA Ã€ API OPENAI
-------------------------

MÃ©todo: async callGPT5Mini(context)
Linha: 1020

REQUEST:
```javascript
const response = await fetch('/api/assistant/chat', {
    method: 'POST',
    headers: {
        'Content-Type': 'application/json',
    },
    credentials: 'include',
    body: JSON.stringify({
        messages: context.messages,
        model: 'gpt-5-mini',
        reasoning_effort: 'medium',
        max_completion_tokens: 4096,
        temperature: 0.7,
        restaurant_id: this.restaurantData.id,
        session_id: this.sessionId
    })
});
```

RESPONSE HANDLING:
```javascript
if (!response.ok) {
    throw new Error(`Erro na API: ${response.status}`);
}

const data = await response.json();
return data.response || data.message || 'Desculpe, nÃ£o consegui processar sua mensagem.';
```

5.5 CONSTRUÃ‡ÃƒO DE CONTEXTO
---------------------------

MÃ©todo: buildContext(userMessage)
Linha: 940

O contexto inclui:
1. Prompt do sistema (personalizado ou padrÃ£o)
2. Ãšltimas 10 mensagens da conversa
3. Dados do restaurante
4. Dados do cliente (se disponÃ­vel)
5. MemÃ³ria de chat
6. Estado da conversa

Exemplo de System Prompt:
```
VocÃª Ã© Ana, assistente virtual calorosa e humanizada para o restaurante [Nome].

Seu papel:
- Atender clientes com gentileza
- Tirar dÃºvidas sobre o cardÃ¡pio
- Ajudar a fazer pedidos
- Confirmar endereÃ§os de entrega

Dados do restaurante:
- Nome: [Nome]
- Telefone: [Telefone]
- HorÃ¡rio: [HorÃ¡rio]
- EndereÃ§o: [EndereÃ§o]

Cliente atual:
- Nome: [Nome]
- Telefone: [Telefone]
- EndereÃ§o: [EndereÃ§o]

MemÃ³ria da conversa:
[Dados da memÃ³ria]

Estado da conversa: [stage]
```

5.6 PROCESSAMENTO DE RESPOSTAS
-------------------------------

MÃ©todo: async processGPTResponse(response, userMessage)
Linha: 1052

AÃ‡Ã•ES ESPECIAIS DETECTADAS:

1. FINALIZAR PEDIDO:
   - Detecta: 'action":"finalizar' ou 'finalizar pedido'
   - AÃ§Ã£o: Chama createOrder()
   - Incrementa contador de pedidos

2. CONSULTAR CARDÃPIO:
   - Detecta: 'consulta_sistema' ou palavras 'cardÃ¡pio'/'menu'
   - AÃ§Ã£o: Chama getRestaurantMenu()
   - Formata resposta com produtos

CÃ³digo:
```javascript
async processGPTResponse(response, userMessage) {
    // Verificar se precisa criar pedido
    if (response.includes('action":"finalizar') || response.includes('finalizar pedido')) {
        try {
            await this.createOrder();
            this.ordersCreated++;
            document.getElementById('ordersCount').textContent = this.ordersCreated;
        } catch (error) {
            console.error('âŒ Erro ao criar pedido:', error);
            return response + '\n\nOps! Tive um problema ao processar seu pedido. Nosso suporte entrarÃ¡ em contato.';
        }
    }
    
    // Verificar se precisa consultar cardÃ¡pio
    if (response.includes('consulta_sistema') || userMessage.toLowerCase().includes('cardÃ¡pio') || userMessage.toLowerCase().includes('menu')) {
        try {
            const menu = await this.getRestaurantMenu();
            if (menu) {
                return this.formatMenuResponse(menu);
            }
        } catch (error) {
            console.error('âŒ Erro ao buscar cardÃ¡pio:', error);
        }
    }
    
    return response;
}
```

5.7 MEMÃ“RIA DE CHAT
--------------------

A Ana mantÃ©m memÃ³ria persistente usando localStorage.

SALVAMENTO:
```javascript
saveChatMemory() {
    try {
        localStorage.setItem(`ana_memory_${this.sessionId}`, 
            JSON.stringify([...this.chatMemory]));
    } catch (error) {
        console.warn('NÃ£o foi possÃ­vel salvar memÃ³ria de chat:', error);
    }
}
```

CARREGAMENTO:
```javascript
async loadChatMemory() {
    try {
        const savedMemory = localStorage.getItem(`ana_memory_${this.sessionId}`);
        if (savedMemory) {
            this.chatMemory = new Map(JSON.parse(savedMemory));
            this.updateMemoryUI();
        }
    } catch (error) {
        console.warn('NÃ£o foi possÃ­vel carregar memÃ³ria de chat:', error);
    }
}
```

DADOS ARMAZENADOS NA MEMÃ“RIA:
- nome_cliente
- telefone_cliente
- endereco_entrega
- produto_interesse
- forma_pagamento
- ultimo_pedido_id
- estado_conversa

================================================================================
6. ASSISTENTE ADMINISTRATIVO
================================================================================

O assistente administrativo usa o mesmo modelo GPT-5-mini mas com
endpoint e autenticaÃ§Ã£o separados.

DIFERENÃ‡AS:
âœ“ AutenticaÃ§Ã£o administrativa (authenticateAdmin)
âœ“ Acesso a dados privilegiados
âœ“ Sem rate limiting agressivo
âœ“ Retorna mÃ©tricas de uso (usage)
âœ“ Sem integraÃ§Ã£o MCP
âœ“ Flag admin_mode: true

ENDPOINT: POST /api/admin/assistant/chat
Ver seÃ§Ã£o 4.2 para detalhes completos

================================================================================
7. SISTEMA MCP (MODEL CONTEXT PROTOCOL)
================================================================================

O MCP (Model Context Protocol) Ã© um sistema que permite Ã  IA acessar dados
do banco de dados em tempo real para fornecer respostas precisas.

7.1 DETECÃ‡ÃƒO DE PALAVRAS-CHAVE
--------------------------------

FunÃ§Ã£o: detectMCPKeywords(message)
Linha: 5076 (server.js)

PALAVRAS-CHAVE MCP:
- mcp, database, banco de dados
- consulta, query, tabela, dados, sql
- supabase, buscar dados, verificar banco
- consultar base, dados do sistema
- restaurante, restaurant, pedido, order
- cliente, customer, produto, product
- entregador, deliverer, delivery
- cupom, coupon, desconto
- notificacao, notification
- log, atividade, activity
- chat, conversa, message
- prompt, prompit
- administrador, admin, usuario, user
- tipo negocio, business type
- relatorio, report, estatistica
- criar pedido, novo pedido, fazer pedido
- pedido delivery, pedido balcao
- finalizar pedido, processar pedido

CÃ³digo:
```javascript
function detectMCPKeywords(message) {
    const mcpKeywords = [
        'mcp', 'database', 'banco de dados', 'consulta', 'query', 
        'tabela', 'dados', 'sql', 'supabase', 'buscar dados', 
        'verificar banco', 'consultar base', 'dados do sistema',
        'restaurante', 'restaurant', 'pedido', 'order', 'cliente', 'customer',
        'produto', 'product', 'entregador', 'deliverer', 'delivery',
        'cupom', 'coupon', 'desconto', 'notificacao', 'notification',
        'log', 'atividade', 'activity', 'chat', 'conversa', 'message',
        'prompt', 'prompit', 'administrador', 'admin', 'usuario', 'user',
        'tipo negocio', 'business type', 'relatorio', 'report', 'estatistica',
        'criar pedido', 'novo pedido', 'fazer pedido', 'create order', 'new order',
        'pedido delivery', 'pedido balcao', 'balcÃ£o', 'counter order', 'delivery order',
        'finalizar pedido', 'processar pedido', 'salvar pedido', 'complete order'
    ];
    
    const messageNormalized = message.toLowerCase().trim();
    return mcpKeywords.some(keyword => messageNormalized.includes(keyword));
}
```

7.2 EXECUÃ‡ÃƒO DE CONSULTAS MCP
-------------------------------

FunÃ§Ã£o: async executeSupabaseQuery(command, params)
Linha: 5098 (server.js)

COMANDOS SUPORTADOS:

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ list_tables                                                     â”‚
â”‚ Lista todas as tabelas do banco de dados                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ restaurants_data                                                â”‚
â”‚ Retorna dados do restaurante especÃ­fico                        â”‚
â”‚ ParÃ¢metros: restaurant_id                                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ orders_data                                                     â”‚
â”‚ Retorna pedidos do restaurante                                 â”‚
â”‚ ParÃ¢metros: restaurant_id                                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ customers_data                                                  â”‚
â”‚ Retorna clientes do restaurante                                â”‚
â”‚ ParÃ¢metros: restaurant_id                                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ products_data                                                   â”‚
â”‚ Retorna produtos do restaurante                                â”‚
â”‚ ParÃ¢metros: restaurant_id                                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ deliverers_data                                                 â”‚
â”‚ Retorna entregadores do restaurante                            â”‚
â”‚ ParÃ¢metros: restaurant_id                                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ coupons_data                                                    â”‚
â”‚ Retorna cupons do restaurante                                  â”‚
â”‚ ParÃ¢metros: restaurant_id                                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ create_delivery_order                                           â”‚
â”‚ Cria um pedido de delivery                                      â”‚
â”‚ ParÃ¢metros: restaurant_id, customer_name, customer_phone,       â”‚
â”‚             delivery_address, items[], total_amount, etc.       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ create_counter_order                                            â”‚
â”‚ Cria um pedido de balcÃ£o                                        â”‚
â”‚ ParÃ¢metros: restaurant_id, customer_name, items[], etc.         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

7.3 INTEGRAÃ‡ÃƒO COM GPT-5-MINI
-------------------------------

Quando palavras-chave MCP sÃ£o detectadas (linha 3868 server.js):

1. Determinar comando baseado na mensagem:
```javascript
let queryCommand = 'list_tables';
const msg = lastMessage.content.toLowerCase();

if (msg.includes('restaurante') || msg.includes('restaurant')) {
    queryCommand = 'restaurants_data';
} else if (msg.includes('pedido') || msg.includes('order')) {
    queryCommand = 'orders_data';
} else if (msg.includes('cliente') || msg.includes('customer')) {
    queryCommand = 'customers_data';
} // ... etc
```

2. Executar consulta MCP:
```javascript
mcpData = await executeSupabaseQuery(queryCommand, { restaurant_id: restaurant_id });
mcpActivated = true;
```

3. Adicionar dados ao contexto:
```javascript
if (mcpData) {
    const mcpContext = `\n\nğŸ“Š DADOS DO SISTEMA MCP:
${typeof mcpData === 'string' ? mcpData : JSON.stringify(mcpData, null, 2)}

Use esses dados para responder Ã  pergunta do usuÃ¡rio de forma precisa e Ãºtil.`;
    
    // Modificar a Ãºltima mensagem para incluir o contexto MCP
    messages[messages.length - 1].content += mcpContext;
    console.log('âœ… Dados MCP adicionados ao contexto do assistente');
}
```

4. Retornar resposta com flag mcp_activated:
```javascript
res.json({
    response: responseMessage,
    model_used: 'gpt-5-mini',
    reasoning_effort: reasoning_effort || 'medium',
    mcp_activated: true,
    mcp_data: mcpData
});
```

EXEMPLO DE USO:

UsuÃ¡rio: "Quantos pedidos temos hoje?"

1. Sistema detecta palavra-chave "pedidos"
2. Comando MCP: 'orders_data'
3. Consulta banco de dados
4. Retorna: { count: 45, data: [...] }
5. Adiciona ao prompt: "ğŸ“Š DADOS DO SISTEMA MCP: { count: 45, data: [...] }"
6. GPT-5-mini responde: "Hoje temos 45 pedidos no sistema!"

================================================================================
8. PROMPTS PERSONALIZADOS
================================================================================

O sistema permite que cada restaurante tenha seu prÃ³prio prompt personalizado
para adaptar o comportamento da Ana.

8.1 TABELA DO BANCO DE DADOS
------------------------------

Tabela: ai_system_prompts

Estrutura:
```sql
CREATE TABLE ai_system_prompts (
    id UUID PRIMARY KEY,
    restaurant_id UUID REFERENCES restaurants(id),
    prompt_text TEXT NOT NULL,
    is_active BOOLEAN DEFAULT true,
    created_at TIMESTAMP DEFAULT NOW(),
    updated_at TIMESTAMP DEFAULT NOW()
);
```

8.2 ENDPOINT DE CARREGAMENTO (CLIENTE)
---------------------------------------

ENDPOINT: GET /api/assistant/system-prompt
AutenticaÃ§Ã£o: authenticateEvolutionAPI
Rate Limit: 30 requisiÃ§Ãµes / 60 segundos

Query Params:
- restaurant_id: UUID do restaurante

Response (com prompt personalizado):
```json
{
    "hasCustomPrompt": true,
    "prompt": {
        "id": "uuid",
        "restaurant_id": "uuid",
        "prompt_text": "VocÃª Ã© Ana, assistente do Restaurante XYZ...",
        "is_active": true,
        "created_at": "2025-10-07T00:00:00.000Z",
        "updated_at": "2025-10-07T00:00:00.000Z"
    }
}
```

Response (sem prompt personalizado):
```json
{
    "hasCustomPrompt": false,
    "prompt": null
}
```

8.3 ENDPOINT ADMINISTRATIVO
-----------------------------

ENDPOINT: GET /api/admin/system-prompt
AutenticaÃ§Ã£o: authenticateAdmin

Query Params:
- restaurant_id: UUID do restaurante (obrigatÃ³rio)

ENDPOINT: POST /api/admin/system-prompt
AutenticaÃ§Ã£o: authenticateAdmin
Rate Limit: 5 requisiÃ§Ãµes / 60 segundos
CSRF Protection: Sim

Body:
```json
{
    "restaurant_id": "uuid",
    "prompt_text": "VocÃª Ã© Ana, assistente virtual..."
}
```

Response:
```json
{
    "success": true,
    "message": "Prompt personalizado salvo com sucesso",
    "prompt": {
        "id": "uuid",
        "restaurant_id": "uuid",
        "prompt_text": "...",
        "is_active": true,
        "created_at": "...",
        "updated_at": "..."
    }
}
```

8.4 USO NO FRONTEND
--------------------

MÃ©todo: async loadCustomSystemPrompt()
Arquivo: public/js/assistente.js
Linha: 790

CÃ³digo:
```javascript
async loadCustomSystemPrompt() {
    if (this.systemPromptLoaded) return;
    
    try {
        const response = await fetch(`/api/assistant/system-prompt?restaurant_id=${this.restaurantData.id}`, {
            credentials: 'include'
        });
        
        if (!response.ok) {
            console.log('âš ï¸ Nenhum prompt personalizado encontrado, usando prompt padrÃ£o');
            this.systemPromptLoaded = true;
            return;
        }
        
        const data = await response.json();
        
        if (data.hasCustomPrompt && data.prompt?.prompt_text) {
            this.customSystemPrompt = data.prompt.prompt_text;
            console.log('âœ… Prompt personalizado carregado para', this.restaurantData.name);
        } else {
            console.log('ğŸ“ Usando prompt padrÃ£o do sistema');
        }
        
        this.systemPromptLoaded = true;
        
    } catch (error) {
        console.error('âŒ Erro ao carregar prompt personalizado:', error);
        this.systemPromptLoaded = true;
    }
}
```

PROMPT PADRÃƒO (caso nÃ£o haja personalizado):
```
VocÃª Ã© Ana, assistente virtual calorosa e humanizada para o restaurante [Nome].

Seu papel Ã© atender clientes com gentileza, tirar dÃºvidas sobre o cardÃ¡pio,
ajudar a fazer pedidos e confirmar endereÃ§os de entrega.

CaracterÃ­sticas:
- Sempre gentil e atenciosa
- Use emojis moderadamente
- Seja objetiva mas amigÃ¡vel
- Confirme sempre os dados importantes
- Ajude o cliente a escolher produtos

Lembre-se: vocÃª estÃ¡ representando o restaurante, entÃ£o mantenha sempre
um atendimento de excelÃªncia!
```

================================================================================
9. RATE LIMITING E SEGURANÃ‡A
================================================================================

9.1 RATE LIMITING
------------------

Middleware: rateLimitEvolutionAPI(maxRequests, windowMs)

CONFIGURAÃ‡Ã•ES:

Endpoint: /api/assistant/chat
- Limite: 30 requisiÃ§Ãµes
- Janela: 60000ms (60 segundos)
- Por IP ou sessÃ£o

Endpoint: /api/assistant/menu/:restaurantId
- Limite: 30 requisiÃ§Ãµes
- Janela: 60000ms (60 segundos)

Endpoint: /api/assistant/create-order
- Limite: 10 requisiÃ§Ãµes
- Janela: 60000ms (60 segundos)

Endpoint: /api/assistant/product-info
- Limite: 30 requisiÃ§Ãµes
- Janela: 60000ms (60 segundos)

Endpoint: /api/assistant/system-prompt (GET)
- Limite: 30 requisiÃ§Ãµes
- Janela: 60000ms (60 segundos)

Endpoint: /api/assistant/system-prompt (POST)
- Limite: 5 requisiÃ§Ãµes
- Janela: 60000ms (60 segundos)

9.2 AUTENTICAÃ‡ÃƒO
-----------------

CLIENTES:
- Middleware: authenticateEvolutionAPI
- ValidaÃ§Ã£o de sessÃ£o
- VerificaÃ§Ã£o de restaurant_id
- ProteÃ§Ã£o contra acesso nÃ£o autorizado

ADMINISTRADORES:
- Middleware: authenticateAdmin
- AutenticaÃ§Ã£o administrativa
- PermissÃµes elevadas
- Acesso a endpoints privilegiados

9.3 PROTEÃ‡ÃƒO CSRF
------------------

Endpoints protegidos:
- POST /api/assistant/system-prompt
- POST /api/admin/system-prompt

Middleware: csrfProtection

Token CSRF obtido em:
- GET /api/admin/csrf-token

9.4 SEGURANÃ‡A DA API KEY
-------------------------

NUNCA EXPOR:
```javascript
// âŒ ERRADO - Expor a chave
res.json({
    apiKey: process.env.OPENAI_API_KEY  // NUNCA FAZER ISSO
});

// âœ… CORRETO - Manter no servidor
const apiKey = process.env.OPENAI_API_KEY;
// Usar apenas no backend
```

VALIDAÃ‡ÃƒO:
```javascript
const apiKey = process.env.OPENAI_API_KEY;
if (!apiKey) {
    console.error('âŒ OPENAI_API_KEY nÃ£o configurada');
    return res.status(500).json({ 
        error: 'ConfiguraÃ§Ã£o da OpenAI API nÃ£o encontrada' 
    });
}
```

ARMAZENAMENTO:
- VariÃ¡vel de ambiente (process.env)
- Secrets do Replit
- NUNCA em cÃ³digo ou frontend

================================================================================
10. TROUBLESHOOTING
================================================================================

10.1 PROBLEMAS COMUNS
----------------------

PROBLEMA: "OPENAI_API_KEY nÃ£o configurada"
CAUSA: VariÃ¡vel de ambiente nÃ£o definida
SOLUÃ‡ÃƒO:
1. Verificar Secrets no Replit
2. Adicionar OPENAI_API_KEY com valor vÃ¡lido
3. Reiniciar servidor

PROBLEMA: "Erro na OpenAI API: 401"
CAUSA: API key invÃ¡lida ou expirada
SOLUÃ‡ÃƒO:
1. Verificar validade da chave em platform.openai.com
2. Gerar nova chave se necessÃ¡rio
3. Atualizar secret OPENAI_API_KEY

PROBLEMA: "Erro na OpenAI API: 429"
CAUSA: Rate limit da OpenAI excedido
SOLUÃ‡ÃƒO:
1. Aguardar reset do limite
2. Verificar uso em platform.openai.com
3. Considerar upgrade de plano

PROBLEMA: "Timeout na conexÃ£o com OpenAI"
CAUSA: Rede instÃ¡vel ou API temporariamente indisponÃ­vel
SOLUÃ‡ÃƒO:
1. Verificar status em status.openai.com
2. Tentar novamente
3. Implementar retry logic

PROBLEMA: "Ana nÃ£o responde"
CAUSA: Diversos fatores
DEBUG:
1. Verificar console do navegador
2. Verificar logs do servidor
3. Testar endpoint /api/health
4. Verificar se OPENAI_API_KEY estÃ¡ configurada
5. Testar chamada direta Ã  API

PROBLEMA: "Resposta em inglÃªs ao invÃ©s de portuguÃªs"
CAUSA: Prompt do sistema nÃ£o estÃ¡ em portuguÃªs
SOLUÃ‡ÃƒO:
1. Verificar prompt personalizado
2. Garantir que estÃ¡ em pt-BR
3. Adicionar instruÃ§Ã£o explÃ­cita: "Responda SEMPRE em portuguÃªs brasileiro"

PROBLEMA: "MCP nÃ£o estÃ¡ ativando"
CAUSA: Palavras-chave nÃ£o detectadas
SOLUÃ‡ÃƒO:
1. Usar palavras-chave especÃ­ficas (ver seÃ§Ã£o 7.1)
2. Exemplo: "Mostre os dados dos pedidos"
3. Verificar logs: "ğŸ”§ Palavras-chave MCP detectadas"

PROBLEMA: "Prompt personalizado nÃ£o carrega"
CAUSA: Erro na consulta ao banco ou prompt inativo
SOLUÃ‡ÃƒO:
1. Verificar tabela ai_system_prompts
2. Garantir is_active = true
3. Verificar restaurant_id correto
4. Verificar logs do servidor

10.2 LOGS E DEBUGGING
----------------------

LOGS IMPORTANTES:

InicializaÃ§Ã£o:
- "ğŸ”§ Servindo GPT-5-mini config via OpenAI API"
- "âœ… Ana inicializada com sucesso"

Processamento:
- "ğŸ¤– Ana processando mensagem para restaurante {id}"
- "ğŸ”§ Palavras-chave MCP detectadas, executando consulta..."
- "âœ… Ana respondeu para {session_id}"

Erros:
- "âŒ OPENAI_API_KEY nÃ£o configurada"
- "âŒ Erro na OpenAI API:"
- "âŒ Erro no endpoint do assistente:"

VERIFICAR NO CONSOLE:
```javascript
// Status da configuraÃ§Ã£o
console.log('Mapbox Token:', window.MAPBOX_ACCESS_TOKEN);
console.log('Supabase Client:', supabase);

// Estado da Ana
console.log('Ana Messages:', ana.messages);
console.log('Ana Memory:', ana.chatMemory);
console.log('Restaurant Data:', ana.restaurantData);

// Testar endpoint
fetch('/api/config/openai')
    .then(r => r.json())
    .then(console.log);
```

10.3 HEALTH CHECK
------------------

VERIFICAR STATUS:
```bash
curl http://localhost:5000/api/health
```

Response esperada:
```json
{
    "status": "ok",
    "services": {
        "openai": "connected",
        "supabase": "connected",
        "evolution": "connected",
        "mapbox": "connected"
    }
}
```

Se openai != "connected":
- "not_configured": Adicionar OPENAI_API_KEY
- "timeout": Problema de rede
- "error": Verificar validade da chave

10.4 TESTE DE INTEGRAÃ‡ÃƒO
--------------------------

TESTE MANUAL (cURL):
```bash
# Obter CSRF token (se necessÃ¡rio)
curl -X GET http://localhost:5000/api/admin/csrf-token \
  -H "Cookie: session=..." \
  -c cookies.txt

# Testar chat
curl -X POST http://localhost:5000/api/assistant/chat \
  -H "Content-Type: application/json" \
  -H "Cookie: session=..." \
  -d '{
    "messages": [
      {
        "role": "system",
        "content": "VocÃª Ã© Ana, assistente virtual."
      },
      {
        "role": "user",
        "content": "OlÃ¡!"
      }
    ],
    "model": "gpt-5-mini",
    "restaurant_id": "uuid-do-restaurante",
    "session_id": "test-123"
  }'
```

TESTE VIA JAVASCRIPT (Console):
```javascript
// No console do navegador
fetch('/api/assistant/chat', {
    method: 'POST',
    headers: {
        'Content-Type': 'application/json'
    },
    credentials: 'include',
    body: JSON.stringify({
        messages: [
            { role: 'system', content: 'VocÃª Ã© Ana.' },
            { role: 'user', content: 'OlÃ¡!' }
        ],
        model: 'gpt-5-mini',
        restaurant_id: 'uuid',
        session_id: 'test'
    })
})
.then(r => r.json())
.then(console.log);
```

================================================================================
RESUMO EXECUTIVO
================================================================================

MODELO: GPT-5-mini
PROVIDER: OpenAI (https://api.openai.com/v1)
CHAVE: OPENAI_API_KEY (variÃ¡vel de ambiente)

ENDPOINTS PRINCIPAIS:
âœ“ POST /api/assistant/chat (clientes)
âœ“ POST /api/admin/assistant/chat (administradores)
âœ“ GET /api/config/openai (configuraÃ§Ã£o pÃºblica)
âœ“ GET /api/health (status)

ASSISTENTES:
âœ“ Ana - Assistente Virtual (clientes)
âœ“ Assistente Administrativo (gestÃ£o)

RECURSOS ESPECIAIS:
âœ“ MCP - Model Context Protocol (acesso a dados)
âœ“ Prompts personalizados por restaurante
âœ“ MemÃ³ria de conversa persistente
âœ“ Rate limiting configurÃ¡vel
âœ“ IntegraÃ§Ã£o com Supabase

PARÃ‚METROS TÃPICOS:
- model: 'gpt-5-mini'
- max_completion_tokens: 4096
- temperature: 0.7
- reasoning_effort: 'medium'
- stream: false

SEGURANÃ‡A:
âœ“ API key protegida no servidor
âœ“ AutenticaÃ§Ã£o obrigatÃ³ria
âœ“ Rate limiting ativo
âœ“ CSRF protection em endpoints de escrita
âœ“ ValidaÃ§Ã£o de restaurant_id

RATE LIMITS:
- Chat: 30 req/min
- CriaÃ§Ã£o de pedidos: 10 req/min
- Salvamento de prompts: 5 req/min

================================================================================
FIM DA DOCUMENTAÃ‡ÃƒO
================================================================================

Ãšltima atualizaÃ§Ã£o: 07/10/2025
VersÃ£o do sistema: TimePulse AI 1.0.0
Modelo: GPT-5-mini
Desenvolvido por: TimePulse Team

Para suporte adicional, consulte:
- DocumentaÃ§Ã£o OpenAI: https://platform.openai.com/docs
- Status da API: https://status.openai.com
- Dashboard: https://platform.openai.com/account/usage
